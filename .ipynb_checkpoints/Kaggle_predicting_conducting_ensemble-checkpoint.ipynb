{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a9c50b60-cc4a-43f7-b14d-c942930999d4",
    "_uuid": "40a9be2efa9d07ee572271be66462e91917afa0b"
   },
   "source": [
    "**Nomad2018 Predicting Transparent Conductors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5f95e937-d9a2-47b2-87b5-34422cee4a4d",
    "_uuid": "b59e165dffc2c86fb53e79767d02e4332df6b356"
   },
   "source": [
    "# 1. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "299b75ec-e8de-458d-86fe-40d7d899635f",
    "_uuid": "21358e391044c9ba4e1c3d0a9e983fb483438fdf"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-249f524e4c9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "%matplotlib inline\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "import catboost as cboost\n",
    "import lightgbm as lgb\n",
    "from lightgbm import Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3876183b-d669-4dd1-ae21-07a65a6af157",
    "_uuid": "a4c450aeb18e739d15c5e05b7d54edacb12921df",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "60b0f8be-7f3c-4c7c-a60f-6bcbba7c331f",
    "_uuid": "530fd11c786f420e2661a9d05e1dc054c3c6929f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_df(fin):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        fin (str) - file name with training or test data\n",
    "    Returns:\n",
    "        DataFrame with renamed columns (personal preference)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(fin)\n",
    "    df = df.rename(columns={'spacegroup' : 'sg',\n",
    "                            'number_of_total_atoms' : 'Natoms',\n",
    "                            'percent_atom_al' : 'x_Al',\n",
    "                            'percent_atom_ga' : 'x_Ga',\n",
    "                            'percent_atom_in' : 'x_In',\n",
    "                            'lattice_vector_1_ang' : 'a',\n",
    "                            'lattice_vector_2_ang' : 'b',\n",
    "                            'lattice_vector_3_ang' : 'c',\n",
    "                            'lattice_angle_alpha_degree' : 'alpha',\n",
    "                            'lattice_angle_beta_degree' : 'beta',\n",
    "                            'lattice_angle_gamma_degree' : 'gamma',\n",
    "                            'formation_energy_ev_natom' : 'Ef',\n",
    "                            'bandgap_energy_ev' : 'Eg'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0b703c95-e7e8-4878-86d5-94f6f6288b19",
    "_uuid": "6c9b642396e461e3a18b2d50f0c78aaeb9344aee",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = make_df('../input/train.csv')\n",
    "test  = make_df('../input/test.csv')\n",
    "target = train[['Ef','Eg']]\n",
    "all_data = pd.concat([train.drop(['Ef','Eg'], axis = 1),test], axis = 0, ignore_index=True)\n",
    "all_data.drop(['id'], axis = 1, inplace = True)\n",
    "all_data['is_train'] = [1 if row < train.shape[0] else 0 for row in all_data.index]\n",
    "all_data[all_data['is_train'] == 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1755e2e-d7e6-474e-8d09-3d0a50fd1c9a",
    "_uuid": "a134d4fedf54e35aef5b0ce19096f13e66e2057e"
   },
   "source": [
    "# 2. View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c0e6264f-fd78-4a81-b8f3-dda4ae74146c",
    "_uuid": "7838791e01cc6d6725b6136ed588f6cdd5901288",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9987a329-19d8-45d2-8d3f-82e4731d632a",
    "_uuid": "cfc0a66bf4b93db14137b8b36b52ad13eab6268b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check missing data.\n",
    "print('Missing data in train dataset:')\n",
    "print(np.sum(np.isnan(train)))\n",
    "print('Missing data in test dataset:')\n",
    "print(np.sum(np.isnan(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2e29526c-a209-4d72-8283-caa5bd1a4baf",
    "_uuid": "8d16037e0a9ec0621707ca691ce62395404feabb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# correlation plot\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "corr_train = train.corr()\n",
    "sns.heatmap(corr_train, mask=np.zeros_like(corr_train, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, annot=True, fmt=\".2f\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b3f0dc92-9d94-4c80-851a-2e39a0638428",
    "_uuid": "1791651bb327ae792ec9f72594fa793224e130d2",
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "# 3. Add feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "04a9a04e-0d7a-43c1-9536-f71741610df5",
    "_uuid": "b2233d59a776045a9e574b5e503f29d51f88b2f0"
   },
   "source": [
    "## 3.1 N_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8abd11fe-f184-4e33-bf31-c3378d6a656a",
    "_uuid": "29969e590d97beb7e013ae1ec74d77e2af2fa5d1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_natoms_element(df, x_elm): return np.round(df['Natoms'] * df[x_elm] *0.4)\n",
    "all_data_nonlin = deepcopy(all_data)\n",
    "for x_elm in list(['x_Al', 'x_Ga', 'x_In']):\n",
    "    new_ft = 'n' + x_elm[1:]\n",
    "    all_data_nonlin[new_ft] = add_natoms_element(all_data, x_elm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2bd731ae-828c-493d-9b50-6d6bfe9ca911",
    "_uuid": "f2215067337c65b99ea3ce3eb668878d967dcfed"
   },
   "source": [
    "## 3.2 Polynomial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a44d7fa4-4ca1-4715-9547-c46037e6f03a",
    "_uuid": "f2b8c864aa5342b2bff274d56203e68ad21d2c82",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(2)\n",
    "def add_polynomial(df, poly, feature):\n",
    "    new_X = poly.fit_transform(df[feature])\n",
    "    new_df = pd.DataFrame(new_X, columns=poly.get_feature_names(feature))\n",
    "    df2 = df.drop(feature, axis=1)\n",
    "    df2 = pd.concat([df2, new_df], axis=1)   \n",
    "    return df2\n",
    "\n",
    "def add_cos(df):\n",
    "    df2 = deepcopy(df)\n",
    "    df2['cos_alpha'] = np.cos(df['alpha']/180*np.pi)\n",
    "    df2['cos_beta'] = np.cos(df['beta']/180*np.pi)\n",
    "    df2['cos_gamma'] = np.cos(df['gamma']/180*np.pi)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "33be6eda-45c3-4c54-a7f6-aff6e8d4c90d",
    "_uuid": "5edd38ec3ea56d515cfa10938cb1d0f6a9cc0bf6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_nonlin2 = add_cos(all_data_nonlin)\n",
    "#feature = ['a', 'b', 'c', 'sin_alpha', 'sin_beta', 'sin_gamma']\n",
    "#add_polynomial(df, poly, feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "aab6bd89-d70c-4098-b6ea-9eac2fbfa6db",
    "_uuid": "b5c48d77ebf27d913474c8d412d61bcd69d5b34d"
   },
   "source": [
    "## 3.3 **Calculate Bond Length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "01d35df9-2e9e-4cef-841a-470cd171694b",
    "_uuid": "27e56dbfaaf405a839f75b48f4a2774c3cb9c058",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_xyz(filename):\n",
    "    \"\"\"\n",
    "    get geometric data from xyz file\n",
    "    \"\"\"\n",
    "    pos = []   # atomic positions\n",
    "    lat = []   # lattice constant\n",
    "    with open(filename) as f:\n",
    "        for line in f.readlines():\n",
    "            l = line.split()\n",
    "            if l[0] == 'atom':\n",
    "                pos.append([np.array(l[1:4], dtype=np.float),l[4]])\n",
    "            elif l[0] == 'lattice_vector':\n",
    "                lat.append(np.array(l[1:4], dtype=np.float))\n",
    "    return pos, np.array(lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "861044c5-f28c-4966-b7ef-9079aab00675",
    "_uuid": "b39c349264a5e8aa152c410f508361e8a85b01be",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_MO_bond(xyz_M, xyz_O, lat, bond_length):\n",
    "    \"\"\"\n",
    "    calculate Metal-Oxygen bond length, and MO bond vector\n",
    "    \"\"\"\n",
    "    lat_inv = np.linalg.inv(lat)\n",
    "    bonds_len_MO = []\n",
    "    bonds_MO = []\n",
    "    bonds_vector = []\n",
    "    for atom_M in xyz_M:\n",
    "        # set margin, the distance from (x0, y0) to a line (y = kx): d = |k*x0-y0|/sqrt(k^2+1)\n",
    "        # or transfer cartesian coordinates to direct coordinates:\n",
    "        xyz_O2 = deepcopy(xyz_O)\n",
    "        dir_atom_M = np.dot(atom_M, lat_inv)\n",
    "        for co_ind in range(3):\n",
    "            if dir_atom_M[co_ind] < 0.2:\n",
    "                xyz_O2 = np.vstack([xyz_O2, xyz_O2-lat[co_ind]])\n",
    "            elif dir_atom_M[co_ind] > 0.8:\n",
    "                xyz_O2 = np.vstack([xyz_O2, xyz_O2+lat[co_ind]])\n",
    "        for atom_O in xyz_O:\n",
    "            d = np.linalg.norm(atom_M - atom_O)   # distance between M-O\n",
    "            if d < bond_length:\n",
    "                bonds_len_MO.append(d)\n",
    "                bonds_MO.append(atom_O - atom_M)\n",
    "            else:\n",
    "                pass\n",
    "    if not bonds_len_MO:\n",
    "        bonds_len_MO = [0]\n",
    "    if not bonds_MO:\n",
    "        bonds_MO = [[0,0,0],[0,0,0]]\n",
    "    return np.array(bonds_len_MO), np.array(bonds_MO) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0f279da2-c233-4dcf-ab2c-56fea86ed85e",
    "_uuid": "d4bc843bbbcea42346351200a36f5029b8e780b2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_xyz_atom(df_name, sample_id):\n",
    "    \"\"\"\n",
    "    get Ga-O, Al-O and In-O bonds from xyz files for a data frame\n",
    "    Args:\n",
    "        df_name (str) - data frame name, e.g. 'train'\n",
    "        df_id (list) - data frame id, e.g. train['id']\n",
    "        bond_length (float) - bond length threshold\n",
    "    Return:\n",
    "        bond length lists for Ga-O, AlO and InO bonds (np.array)\n",
    "    \"\"\"\n",
    "    fn = \"../input/\" + df_name + \"/{}/geometry.xyz\".format(sample_id)\n",
    "    df_pos, df_lat = get_xyz(fn)\n",
    "\n",
    "    # coordinate list for each element\n",
    "    xyz_Ga = []\n",
    "    xyz_Al = []\n",
    "    xyz_In = []\n",
    "    xyz_O  = []\n",
    "\n",
    "    for atom in df_pos:\n",
    "        if atom[1] == 'Ga':\n",
    "            xyz_Ga.append(atom[0])\n",
    "        elif atom[1] == 'Al':\n",
    "            xyz_Al.append(atom[0])\n",
    "        elif atom[1] == 'In':\n",
    "            xyz_In.append(atom[0])\n",
    "        elif atom[1] == 'O':\n",
    "            xyz_O.append(atom[0])\n",
    "    \n",
    "    return df_pos, df_lat, np.array(xyz_Ga), np.array(xyz_Al), np.array(xyz_In), np.array(xyz_O)\n",
    "                \n",
    "def get_bonds(df_name, df_id, bond_length):\n",
    "    bonds_len_GaO = []\n",
    "    bonds_len_AlO = []\n",
    "    bonds_len_InO = []\n",
    "    bonds_GaO = []\n",
    "    bonds_AlO = []\n",
    "    bonds_InO = []\n",
    "    for sample_id in df_id:\n",
    "        pos, lat, xyz_Ga, xyz_Al, xyz_In, xyz_O = get_xyz_atom(df_name, sample_id) \n",
    "        bond_len_GaO, bond_GaO = calc_MO_bond(xyz_Ga, xyz_O, lat, bond_length)\n",
    "        bond_len_AlO, bond_AlO = calc_MO_bond(xyz_Al, xyz_O, lat, bond_length)\n",
    "        bond_len_InO, bond_InO = calc_MO_bond(xyz_In, xyz_O, lat, bond_length)\n",
    "        bonds_len_GaO.append(bond_len_GaO)\n",
    "        bonds_len_AlO.append(bond_len_AlO)\n",
    "        bonds_len_InO.append(bond_len_InO)\n",
    "        bonds_GaO.append(np.mean(bond_GaO, axis=0))\n",
    "        bonds_AlO.append(np.mean(bond_AlO, axis=0))\n",
    "        bonds_InO.append(np.mean(bond_InO, axis=0))\n",
    "    return bonds_len_GaO, bonds_len_AlO, bonds_len_InO, bonds_GaO, bonds_AlO, bonds_InO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fb56791a-f7af-4537-84e0-a996963bc546",
    "_uuid": "ff71f267aa8b9fe6344199a259222c615d787df3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BOND_LEN = 2.5   # bond length threshold\n",
    "%time train_len_GaO, train_len_AlO, train_len_InO, train_bonds_GaO, train_bonds_AlO, train_bonds_InO = get_bonds('train', train['id'], BOND_LEN)\n",
    "%time test_len_GaO, test_len_AlO, test_len_InO, test_bonds_GaO, test_bonds_AlO, test_bonds_InO = get_bonds('test', test['id'], BOND_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c4f106b4-15a9-41f9-9f16-f7091ac45750",
    "_uuid": "dee5fd8cf2779eb7beb442c36a2271b9104b4b78",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bond_features(bonds, name):\n",
    "    \"\"\"\n",
    "    calculate bond features from bond data sets\n",
    "    Args:\n",
    "        bonds (list) - bond length list\n",
    "        name (str) - bond name, e.g. 'gao'\n",
    "    Return:\n",
    "        df_bond_features (pd.DataFrame) - bond features\n",
    "    \"\"\"\n",
    "    n_bonds = []       # number of bonds\n",
    "    len_bonds = []\n",
    "    for i in range(len(bonds)):\n",
    "        if np.mean(bonds[i]) == 0:\n",
    "            n_bonds.append(0)\n",
    "            len_bonds.append(0)\n",
    "        else:\n",
    "            n_bonds.append(len(bonds[i]))\n",
    "            len_bonds.append(np.mean(bonds[i]))\n",
    "        df_bond_features = pd.DataFrame({'n_bonds_' + name:n_bonds,'len_bonds_' + name:len_bonds})\n",
    "    return df_bond_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d83007e5-d9a7-43bf-800c-77c99406f6c1",
    "_uuid": "97c94ae51cfbfee6326d178ced875bca5665fb3f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_bond_features_GaO = get_bond_features(train_len_GaO, 'GaO')\n",
    "train_bond_features_AlO = get_bond_features(train_len_AlO, 'AlO')\n",
    "train_bond_features_InO = get_bond_features(train_len_InO, 'InO')\n",
    "\n",
    "test_bond_features_GaO = get_bond_features(test_len_GaO, 'GaO')\n",
    "test_bond_features_AlO = get_bond_features(test_len_AlO, 'AlO')\n",
    "test_bond_features_InO = get_bond_features(test_len_InO, 'InO')\n",
    "\n",
    "all_bond_GaO = pd.concat([train_bond_features_GaO, test_bond_features_GaO], axis=0, ignore_index=True)\n",
    "all_bond_AlO = pd.concat([train_bond_features_AlO, test_bond_features_AlO], axis=0, ignore_index=True)\n",
    "all_bond_InO = pd.concat([train_bond_features_InO, test_bond_features_InO], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "14814dda-5c6a-42e6-ae43-d7f8640e8a89",
    "_uuid": "c19c1c608aa2519b6cb814939fdf2f891219cc96",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b5f41b48-7ca6-47ee-b8e9-ee92ee238c18",
    "_uuid": "a4a6d54e3d04da9e3b5ff0d78cea1fdec270b661",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_bond_per_atom(df):\n",
    "    df2 = deepcopy(df)\n",
    "    #num1 = df['n_Al'].values\n",
    "    #num1[num1 == 0] += 1\n",
    "    #num2 = df['n_Ga'].values\n",
    "    #num2[num2 == 0] += 1\n",
    "    #num3 = df['n_In'].values\n",
    "    #num3[num3 == 0] += 1\n",
    "    #df2['bonds_per_Al'] = df['n_bonds_AlO']/num1\n",
    "    #df2['bonds_per_Ga'] = df['n_bonds_GaO']/num2\n",
    "    #df2['bonds_per_In'] = df['n_bonds_InO']/num3\n",
    "    df2['n_bonds'] = df['n_bonds_AlO']+df['n_bonds_GaO']+df['n_bonds_InO']\n",
    "    df2['bonds_per_atom'] = (df['n_bonds_AlO']+df['n_bonds_GaO']+df['n_bonds_InO'])/df['Natoms']\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "482f7e7f-125c-4215-b70c-8f2d306c0408",
    "_uuid": "c4da115028d78f114684b165549afb470944b89d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bond_vector(train_bond_features_GaO, train_bond_features_AlO, train_bond_features_InO, bonds_Ga, bonds_Al, bonds_In):\n",
    "    new_vector = np.hstack([bonds_Ga, bonds_Al, bonds_In])\n",
    "    n_Ga = train_bond_features_GaO['n_bonds_GaO'].values\n",
    "    n_Al = train_bond_features_AlO['n_bonds_AlO'].values\n",
    "    n_In = train_bond_features_InO['n_bonds_InO'].values\n",
    "    mean_vector=[]\n",
    "    for i in range(len(n_Ga)):\n",
    "        mean_v = (n_Ga[i]*bonds_Ga[i]+n_Al[i]*bonds_Al[i]+n_In[i]*bonds_In[i])/(n_Ga[i]+n_Al[i]+n_In[i])\n",
    "        mean_vector.append(mean_v)\n",
    "    new_vector = np.hstack([new_vector, mean_vector])\n",
    "    df_vector = pd.DataFrame(new_vector, columns = ['bond_Ga_x','bond_Ga_y','bond_Ga_z',\n",
    "                                                   'bond_Al_x','bond_Al_y','bond_Al_z',\n",
    "                                                   'bond_In_x','bond_In_y','bond_In_z',\n",
    "                                                   'bond_x','bond_y','bond_z',])\n",
    "    df2_vector = pd.DataFrame(np.array(mean_vector), columns = ['bond_x','bond_y','bond_z'])\n",
    "    return df2_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0db53785-60fa-46d5-9454-632c48aa69c5",
    "_uuid": "647f2d10995788bcae0378816944ef19ec16c298",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_vector = make_bond_vector(train_bond_features_GaO, train_bond_features_AlO, train_bond_features_InO, \n",
    "                 train_bonds_GaO, train_bonds_AlO, train_bonds_InO)\n",
    "df_test_vector = make_bond_vector(test_bond_features_GaO, test_bond_features_AlO, test_bond_features_InO, \n",
    "                 test_bonds_GaO, test_bonds_AlO, test_bonds_InO)\n",
    "all_vector = pd.concat([df_train_vector, df_test_vector], axis=0, ignore_index=True)\n",
    "all_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3d7e6aeb-7308-45c3-9bde-0c69cebc2003",
    "_uuid": "a395eb2e181fccc7788beb778c0b850a1ce2cd12",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add bond features to data sets\n",
    "all_data_bond = pd.concat([all_data_nonlin2, all_bond_GaO, all_bond_AlO, all_bond_InO, all_vector], axis=1)\n",
    "all_data_bond = add_bond_per_atom(all_data_bond)\n",
    "all_data_bond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1ab9f5c-6b9a-45b0-aa17-cd898d68e883",
    "_uuid": "30deb9a1420a6f3b210d5c15e71ae3265b0a22e1",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6f45fad0-b385-4bcc-ac67-2fcacc4fe390",
    "_uuid": "b844dd512aac8214f386b54c799dd8973e1f47e3"
   },
   "source": [
    "## 3.4 Volumn and density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7070d8c3-a611-405b-8fc7-7d966ed192d9",
    "_uuid": "9a703ae1fb9da34f80bb251f68e70083fbd38dfc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vol(a, b, c, alpha, beta, gamma):\n",
    "    \"\"\"\n",
    "    calculate the volume of the structure\n",
    "    Args:\n",
    "        a (float) - lattice vector 1\n",
    "        b (float) - lattice vector 2\n",
    "        c (float) - lattice vector 3\n",
    "        alpha (float) - lattice angle 1 [radians]\n",
    "        beta (float) - lattice angle 2 [radians]\n",
    "        gamma (float) - lattice angle 3 [radians]\n",
    "    Returns:\n",
    "        volume (float) of the parallelepiped unit cell\n",
    "    \"\"\"\n",
    "    alpha = np.pi*alpha/180\n",
    "    beta = np.pi*beta/180\n",
    "    gamma = np.pi*gamma/180\n",
    "    vol = a*b*c*np.sqrt(1 + 2*np.cos(alpha)*np.cos(beta)*np.cos(gamma)\n",
    "                           - np.cos(alpha)**2\n",
    "                           - np.cos(beta)**2\n",
    "                           - np.cos(gamma)**2)\n",
    "    return vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "05da5fb9-5e96-4265-b9a3-e5176db0e94f",
    "_uuid": "944d4231c29b40b3ad296a87acc97f2131212530",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the cell volume\n",
    "all_data_vol = deepcopy(all_data_bond)\n",
    "all_data_vol['vol'] = get_vol(all_data_bond['a'], all_data_bond['b'], all_data_bond['c'], \n",
    "                              all_data_bond['alpha'], all_data_bond['beta'], all_data_bond['gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b58b4313-48d8-470f-90ed-c9889b0ee7f7",
    "_uuid": "22fa78da5daabe09b9c7636ff7ab26304a736d87",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the atomic density\n",
    "all_data_vol['density_Ga'] = all_data_vol['n_Ga']/all_data_vol['vol']\n",
    "all_data_vol['density_Al'] = all_data_vol['n_Al']/all_data_vol['vol']\n",
    "all_data_vol['density_In'] = all_data_vol['n_In']/all_data_vol['vol']\n",
    "all_data_vol['density'] = all_data_vol['Natoms']/all_data_vol['vol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ddf8dbcf-9ae5-496c-a3f1-cccffb88ba19",
    "_uuid": "6f2b4e7a4142f97f89438e2267a7582e2da0a214",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1a25661f-81c1-40b3-bd0b-d7dbcad5ebf0",
    "_uuid": "9a417e0c9c5d7fe5de3140890a9bc21c61416e40",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_encode = pd.get_dummies(all_data_vol, columns=['sg'])\n",
    "all_data_encode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4bc98eb1-9267-4703-9754-ffa01244929d",
    "_uuid": "4333b232863198252c90c7cb58503aafe1456b02",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "777b2576-5844-452a-98a3-513449b0ffa0",
    "_uuid": "3f3fce8b9022ef324cd23dc740e290f0562e091d"
   },
   "source": [
    "pca = PCA()\n",
    "pca_data = pca.fit_transform(train_pca_try)\n",
    "cs = pca.explained_variance_ratio_.cumsum()\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "53d31fad-455b-48e1-85bc-14e06e1495b2",
    "_uuid": "4da5d36f8b859dd5d1b357668976cffec9d74e12",
    "collapsed": true
   },
   "source": [
    "pca = PCA(n_components=13)\n",
    "train_score = pca.fit_transform(train_pca_try)\n",
    "test_score = pca.transform(test_pca_try)\n",
    "\n",
    "column_name = ['PC{}'.format(i) for i in range(1,14)]\n",
    "train_pca = pd.DataFrame(train_score,columns=column_name)\n",
    "test_pca = pd.DataFrame(test_score,columns=column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2410acf6-0114-4faa-9c5d-c91f106fee61",
    "_uuid": "7da8c63b90e83aa8c32754d0de1fb33ea85bfef9"
   },
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9077bfd5-4631-4240-a3ad-6bc322353c54",
    "_uuid": "8a4aee1ef5a4127a1b437c18c2624c5863f31bf4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ub = all_data_vol.groupby('is_train').get_group(1).drop(['is_train'],axis=1)\n",
    "test_ub = all_data_vol.groupby('is_train').get_group(0).drop(['is_train'],axis=1)\n",
    "train_ub_encode = all_data_encode.groupby('is_train').get_group(1).drop(['is_train'],axis=1)\n",
    "test_ub_encode = all_data_encode.groupby('is_train').get_group(0).drop(['is_train'],axis=1)\n",
    "train_ub.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6cf4d34c-6616-446f-b7d2-89706d81e0d0",
    "_uuid": "c46d1cbc96bd9a2929eee13e24ca9619fe9231a5"
   },
   "source": [
    "## 4.1 GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2b6e4e63-5ebe-45d2-aff1-2f3b9f713c02",
    "_uuid": "0146e5f2200464a93aa044b7a2a5aa7bcf267b7b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "#from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# uses baysian optimization to find model parameters\n",
    "\n",
    "#model = GradientBoostingRegressor(\n",
    "# loss='ls',\n",
    "# learning_rate = 0.007,\n",
    "# max_depth=23,\n",
    "# n_estimators=30275,\n",
    "# max_features=9,\n",
    "# min_samples_leaf=22,\n",
    "# min_samples_split=15,\n",
    "# min_weight_fraction_leaf=0.0102470171519909\n",
    "#)\n",
    "\n",
    "#search_params = {\n",
    "# \"n_estimators\": np.random.randint(1000, 4000, size=40),\n",
    "# 'max_depth': np.random.randint(2, 40, size=40),\n",
    "# 'min_samples_split': np.random.randint(2, 15, size=15),\n",
    "# 'min_samples_leaf': np.random.randint(2, 50, size=50),\n",
    "# 'min_weight_fraction_leaf': np.random.rand(20)*0.5,\n",
    "# 'max_features': np.random.randint(2, 20, size=20)\n",
    "#}\n",
    "#opt = RandomizedSearchCV(model, search_params, n_iter=50)\n",
    "#opt.fit(train_ub, target['Eg'])\n",
    "#opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "59d811a1-9087-4082-979c-ef6c3235a83b",
    "_uuid": "251d51ac03b3f9326311966658b75047c84c576d",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "da029d24-ce4d-43f0-9c50-6d3c017e4080",
    "_uuid": "bd6f2049f0da094a0957638c6657f7bc59f309bd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "def runGBM1(X_train, y_train, X_valid, y_valid, depth, X_test):\n",
    "    model = GradientBoostingRegressor(\n",
    "     loss='ls',\n",
    "     learning_rate = 0.005,\n",
    "     max_depth=16,\n",
    "     n_estimators=2415,\n",
    "     max_features=18,\n",
    "     min_samples_leaf=5,\n",
    "     min_samples_split=2,\n",
    "     min_weight_fraction_leaf=0.059819807895837962\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    y_pred = model.predict(X_test)\n",
    "    proc=[]\n",
    "    return y_valid_pred, model, y_pred, proc\n",
    "\n",
    "def runGBM2(X_train, y_train, X_valid, y_valid, depth, X_test):\n",
    "    model = GradientBoostingRegressor(\n",
    "     loss='ls',\n",
    "     learning_rate = 0.007,\n",
    "     max_depth=38,\n",
    "     n_estimators=2756,\n",
    "     max_features=18,\n",
    "     min_samples_leaf=13,\n",
    "     min_samples_split=12,\n",
    "     min_weight_fraction_leaf=0.078101303669474154\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    y_pred = model.predict(X_test)\n",
    "    proc=[]\n",
    "    return y_valid_pred, model, y_pred, proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a5db9863-fa4f-426a-8a31-39f9382f7a44",
    "_uuid": "b13fc0b5beb71d550c11c0d77265b5f37817c1c0"
   },
   "source": [
    "## 4.2 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "50d1050f-6699-476c-9af4-d1a63b438ffa",
    "_uuid": "ba2ea0e40f5e4d714552225edcb031c5ebc624b7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find useful parameters for model\n",
    "\n",
    "model = lgb.LGBMRegressor(\n",
    "    objective= 'regression',\n",
    "    boosting_type= 'gbdt',\n",
    "    learning_rate= 0.008,\n",
    "#    num_boost_round = 2000,\n",
    "#    num_threads=1,\n",
    "    bagging_fraction=0.50173,\n",
    "    bagging_freq= 14,\n",
    "    feature_fraction= 0.62509,\n",
    "    lambda_l2= 0.0086298,\n",
    "    #                 max_depth=10,\n",
    "    num_leaves=196\n",
    ")\n",
    "\n",
    "search_params = {\n",
    "    'max_depth': np.random.randint(2, 100, size=50),\n",
    "    'num_leaves': np.random.randint(20, 200, size=50),\n",
    "#    'learning_rate': 0.005,\n",
    "    'feature_fraction': np.random.rand(20)*0.5 + 0.5,\n",
    "    'bagging_fraction': np.random.rand(20)*0.5 + 0.5,\n",
    "    'bagging_freq': np.random.randint(5,15,size=20),\n",
    "#    'num_threads': -1,\n",
    "    'lambda_l2': 10**(np.random.rand(20)*3 -5) ,\n",
    "    'lambda_l1': 10**(np.random.rand(20)*3 -5),\n",
    "#    'num_iterations': np.random.randint(200,4000,size=40)\n",
    "}\n",
    "\n",
    "opt=RandomizedSearchCV(model, search_params, n_iter=50)\n",
    "opt.fit(train_ub, target['Eg'])\n",
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "43c33c85-457f-464b-809c-975b3e661b03",
    "_uuid": "b6f05315d0fefbd7b0ab2319e6ded86a123537d7",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d4789205-1ce1-4e06-8ad1-65d9f979580e",
    "_uuid": "208948b1553ead83a92ba4c7e63a86321831010f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "def runLGB1(X_train, y_train, X_valid, y_valid, depth, X_test):\n",
    "    model = lgb.LGBMRegressor(\n",
    "        objective= 'regression',\n",
    "        boosting_type= 'gbdt',\n",
    "        learning_rate= 0.005,\n",
    "        num_boost_round = 2000,\n",
    "        bagging_fraction=0.97568997363222598,\n",
    "        bagging_freq= 12,\n",
    "        feature_fraction= 0.88107454123473961,\n",
    "        lambda_l1= 0.00044194713707868021\n",
    "        lambda_l2= 3.0877171160978033e-05\n",
    "        max_depth=19,\n",
    "        num_leaves=180\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    y_pred = model.predict(X_test)\n",
    "    proc=[]\n",
    "    return y_valid_pred, model, y_pred, proc\n",
    "\n",
    "def runLGB2(X_train, y_train, X_valid, y_valid, depth, X_test):\n",
    "    model = GradientBoostingRegressor(\n",
    "     loss='ls',\n",
    "     learning_rate = 0.007,\n",
    "     max_depth=38,\n",
    "     n_estimators=2756,\n",
    "     max_features=18,\n",
    "     min_samples_leaf=13,\n",
    "     min_samples_split=12,\n",
    "     min_weight_fraction_leaf=0.078101303669474154\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    y_pred = model.predict(X_test)\n",
    "    proc=[]\n",
    "    return y_valid_pred, model, y_pred, proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "11b68f6f-6b92-475f-8a61-ec86db9d97fd",
    "_uuid": "03abc353a2198fd874653d6f09a0ed32acd9856a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cat_feature = ['sg']\n",
    "#cat_feature_idx = [all_data_vol.columns.get_loc(c) for c in all_data_vol.columns if c in cat_feature]\n",
    "def runXGB(train_X, train_y, test_X, test_y, depth, X_test, feature_names=None, seed_val=123, num_rounds=300):\n",
    "    param = {}\n",
    "    param['booster'] = 'gbtree'\n",
    "    param['objective'] = 'reg:linear'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = depth\n",
    "    param['silent'] = 1\n",
    "    param['eval_metric'] = 'rmse'\n",
    "    param['min_child_weight'] = 1\n",
    "    param['gamma'] = 0\n",
    "    param['subsample'] = 0.8\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "    xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "    watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "    progress = dict()\n",
    "    model = xgb.train(plst, xgtrain, num_rounds, watchlist, evals_result=progress, early_stopping_rounds=10)\n",
    "    \n",
    "    y_valid_pred = model.predict(xgtest, ntree_limit=model.best_ntree_limit)\n",
    "    y_pred = model.predict(xgb.DMatrix(X_test), ntree_limit=model.best_ntree_limit)\n",
    "    return y_valid_pred, model, y_pred, progress\n",
    "\n",
    "\n",
    "\n",
    "def runCatBoost(X_train, y_train, X_valid, y_valid, depth, X_test):\n",
    "    model = cboost.CatBoostRegressor(iterations = 300,\n",
    "                              learning_rate = 0.03,\n",
    "                              depth = depth,\n",
    "                              loss_function = 'RMSE',\n",
    "                              eval_metric = 'RMSE',\n",
    "                              #random_seed = 123,\n",
    "                              od_type = 'Iter',\n",
    "                              od_wait = 10)\n",
    "    cat_feature = ['sg', 'Natoms']\n",
    "    cat_feature_idx = [X_train.columns.get_loc(c) for c in X_train.columns if c in cat_feature]\n",
    "    model.fit(X_train, y_train, cat_features=cat_feature_idx, eval_set=(X_valid, y_valid), plot=True)\n",
    "    #model.fit(X_train, y_train, eval_set=(X_valid, y_valid), plot=True)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_valid_pred, model, y_pred\n",
    "\n",
    "def rmse(actual, predict):\n",
    "    return np.sqrt(np.mean((actual-predict)**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "45762d4e-bdd2-4cb4-beca-3fadd7471084",
    "_uuid": "895d91ad32dd0e938bf152143c90cee175d9cd93",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = target\n",
    "ylog = np.log1p(y)\n",
    "ylog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3eef1e63-ecf6-484f-9fe3-b7be204cdc87",
    "_uuid": "7bd92c137ed359f79d65f9ce68c0265c786270e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K-fold cross-validation\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "def k_fold_cv(X, y, X_test, method, k, depth):\n",
    "    y_pred_sum = 0\n",
    "    list_rmsle = []\n",
    "    count = 0\n",
    "    y_preds = []\n",
    "    models = []\n",
    "    kf = model_selection.KFold(n_splits=k, shuffle=True)\n",
    "    progress = []\n",
    "    for dev_idx, val_idx in kf.split(X):\n",
    "        #regr = RandomForestRegressor(max_depth=depth)\n",
    "        X_train, X_val = X.loc[dev_idx], X.loc[val_idx]\n",
    "        y_train, y_val = y.loc[dev_idx], y.loc[val_idx]\n",
    "        \n",
    "        # feature selection\n",
    "        #regr.fit(X_train, y_train)\n",
    "        #model = SelectFromModel(regr, prefit=True)\n",
    "        #X_train_sel = model.transform(X_train)\n",
    "        #X_val_sel = model.transform(X_val)\n",
    "        #X_test_sel = model.transform(X_test)\n",
    "\n",
    "        #y_pred_valid, model, y_pred, proc = method(X_train_sel, y_train, X_val_sel, y_val, depth, X_test_sel)\n",
    "        y_pred_valid, model, y_pred, proc = method(X_train, y_train, X_val, y_val, depth, X_test)\n",
    "        y_rmsle = rmse(y_val, y_pred_valid)\n",
    "        list_rmsle.append(y_rmsle)\n",
    "        #y_pred = model.predict(X_test)\n",
    "        count += 1\n",
    "        y_pred_sum = y_pred_sum + y_pred\n",
    "        y_preds.append(y_pred)\n",
    "        progress.append(proc)\n",
    "        \n",
    "    rmsle_mean = np.mean(list_rmsle)\n",
    "    print(\"Mean cv score: \", rmsle_mean)\n",
    "    return y_pred_sum/count, y_preds, rmsle_mean, progress\n",
    "\n",
    "# K-fold stacking\n",
    "def k_fold_stacking(X, y, X_test, method, k, depth):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    'X' : 'train', drop target feature. (DataFrame)\n",
    "    'y' : 'target'. (DataFrame)\n",
    "    'X_test' : 'test' , drop 'id' (DataFrame)\n",
    "    'method' : [xgb linear, xgb gbtree, catboost, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "    XGBRegressor]\n",
    "    \"\"\"\n",
    "    y_pred_sum = 0\n",
    "    list_rmsle = []\n",
    "    kf = model_selection.KFold(n_splits=k, shuffle=True, random_state=30)\n",
    "    count = 0\n",
    "    X2 = deepcopy(X)\n",
    "    for dev_idx, val_idx in kf.split(X):\n",
    "        dev_X, val_X = X.loc[dev_idx], X.loc[val_idx]\n",
    "        dev_y, val_y = y.loc[dev_idx], y.loc[val_idx]\n",
    "        y_pred_valid, model = method(dev_X, dev_y, val_X, val_y, depth)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_rmsle = rmse(val_y, y_pred_valid)\n",
    "        X2.loc[val_idx] = y_pred_valid\n",
    "        list_rmsle.append(y_rmsle)\n",
    "        y_pred_sum = y_pred_sum + y_pred\n",
    "        count += 1\n",
    "        \n",
    "    rmsle_mean = np.mean(list_rmsle)\n",
    "    print(\"Mean cv score: \", rmsle_mean)\n",
    "    return X2, y_pred_sum/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d2415127-d5b1-44f5-b1b2-c22731ac2bdb",
    "_uuid": "5c859beb68cc5e953d6256a6781b99d93c27118a",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "93342e8f-01f2-4925-adb1-23bdb8d756b2",
    "_uuid": "aad76d6f67e463a20b1eb36fcd7d33dde6c4b88f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ub = all_data_vol.groupby('is_train').get_group(1).drop(['is_train'],axis=1)\n",
    "test_ub = all_data_vol.groupby('is_train').get_group(0).drop(['is_train'],axis=1)\n",
    "train_ub_encode = all_data_encode.groupby('is_train').get_group(1).drop(['is_train'],axis=1)\n",
    "test_ub_encode = all_data_encode.groupby('is_train').get_group(0).drop(['is_train'],axis=1)\n",
    "train_ub.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "01b40a82-1cd4-41b0-abe5-9f542a67d5c7",
    "_uuid": "314e484f00134b1f2e9b96e54d1692d9ccdc8b5c",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8b3675a4-9512-4cdc-86a7-658e0047b9cd",
    "_uuid": "62a38a9369054917fe7b562f3c2c364dde249a39",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sel_list=[]\n",
    "cat_feature=['sg','Natoms']\n",
    "cell_feature=['x_Al', 'x_Ga', 'x_In', 'a', 'b', 'c', 'alpha', 'beta',\n",
    "       'gamma']\n",
    "nonlin_feature=[ 'n_Al', 'n_Ga', 'n_In', 'cos_alpha', 'cos_beta', 'cos_gamma']\n",
    "bond_feature=['len_bonds_GaO', 'n_bonds_GaO', 'len_bonds_AlO', 'n_bonds_AlO',\n",
    "       'len_bonds_InO', 'n_bonds_InO', 'bond_x', 'bond_y', 'bond_z', 'n_bonds',\n",
    "       'bonds_per_atom']\n",
    "vol_feature=[ 'vol', 'density_Ga', 'density_Al', 'density_In',\n",
    "       'density']\n",
    "sel_list.append(cat_feature+cell_feature)\n",
    "sel_list.append(cat_feature+cell_feature+nonlin_feature)\n",
    "sel_list.append(cat_feature+cell_feature+bond_feature)\n",
    "sel_list.append(cat_feature+cell_feature+vol_feature)\n",
    "sel_list.append(cat_feature+cell_feature+bond_feature+vol_feature)\n",
    "y_preds_Ef=[]\n",
    "y_preds_Eg=[]\n",
    "err1=[]\n",
    "err2=[]\n",
    "#for sel in sel_list:\n",
    "sel = sel_list[-1]\n",
    "#dep_list = [2,4,5]\n",
    "dep_list=[3]\n",
    "for dep in dep_list:\n",
    "    y_pred_Ef, y_pred_Ef_proc, e1, pro1 = k_fold_cv(train_ub[sel], ylog['Ef'], \n",
    "                                        test_ub[sel], runGBM1, 10, dep)\n",
    "    y_pred_Eg, y_pred_Eg_proc, e2, pro2 = k_fold_cv(train_ub[sel], ylog['Eg'], \n",
    "                                        test_ub[sel], runGBM2, 10, dep)\n",
    "#    over_s=[]\n",
    "#    for i in range(len(pro1)):\n",
    "#        p1=pro1[i]\n",
    "#        p2=pro2[i]\n",
    "#        idx = np.argmin(p1['test']['rmse'])\n",
    "#        ratio1 = p1['test']['rmse'][idx]/p1['train']['rmse'][idx]\n",
    "#        idx = np.argmin(p2['test']['rmse'])\n",
    "#        ratio2 = p2['test']['rmse'][idx]/p2['train']['rmse'][idx]\n",
    "#        over_s.append([ratio1, ratio2])\n",
    "#    over_s = np.array(over_s)##\n",
    "#\n",
    "#    fig, ax = plt.subplots(1,2, figsize=[15,5])\n",
    "#    ax[0].plot(over_s[:,0],'--o',color = 'b')\n",
    "#    ax[0].set_title('Ef overfitting with depth = {}'.format(dep))\n",
    "#    ax[1].plot(over_s[:,1],'--o',color = 'r')\n",
    "#    ax[1].set_title('Eg overfitting with depth = {}'.format(dep))\n",
    "\n",
    "    \n",
    "    y_preds_Ef.append(y_pred_Ef)\n",
    "    y_preds_Eg.append(y_pred_Eg)\n",
    "    err1.append(e1)\n",
    "    err2.append(e2)\n",
    "    \n",
    "#    y_pred_Ef, y_pred_Ef_proc, e1, pro1 = k_fold_cv(train_ub_encode, ylog['Ef'], \n",
    "#                                        test_ub_encode, runGBM1, 10, dep)\n",
    "#    y_pred_Eg, y_pred_Eg_proc, e2, pro2 = k_fold_cv(train_ub_encode, ylog['Eg'], \n",
    "#                                        test_ub_encode, runGBM2, 10, dep)\n",
    "#    y_preds_Ef.append(y_pred_Ef)\n",
    "#    y_preds_Eg.append(y_pred_Eg)\n",
    "#    err1.append(e1)\n",
    "#    err2.append(e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f150fd44-8aca-490b-b4a5-652b48a60b94",
    "_uuid": "812c5672904c34b6fcbddfb097168ca21a2d4de8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for iy in range(len(y_preds_Ef)):\n",
    "    y_pred_Ef = y_preds_Ef[iy]\n",
    "    y_pred_Eg = y_preds_Eg[iy]\n",
    "    y_pred_Ef = np.expm1(y_pred_Ef.clip(0))\n",
    "    y_pred_Eg = np.expm1(y_pred_Eg.clip(0))\n",
    "\n",
    "    # submit final predictions\n",
    "    sub = pd.DataFrame()\n",
    "    sub[\"id\"] = test['id']\n",
    "    sub[\"formation_energy_ev_natom\"] = y_pred_Ef\n",
    "    sub[\"bandgap_energy_ev\"] = y_pred_Eg\n",
    "    sub.to_csv(\"catboost_{}.csv\".format(iy), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c2199f9d-a111-4c31-9098-ef1ca11655c5",
    "_uuid": "d9199ab859892e59410d76e9af240b6467020334"
   },
   "outputs": [],
   "source": [
    "y_pred_Ef, e1 = k_fold_cv_cat(train_pca, ylog['Ef'], test_pca, 10, 9)\n",
    "y_pred_Eg, e2 = k_fold_cv_cat(train_pca, ylog['Eg'], test_pca, 10, 7)\n",
    "y_pred_Ef = np.expm1(y_pred_Ef[0].clip(0))\n",
    "y_pred_Eg = np.expm1(y_pred_Eg[0].clip(0))\n",
    "\n",
    "# submit final predictions\n",
    "sub = pd.DataFrame()\n",
    "sub[\"id\"] = test['id']\n",
    "sub[\"formation_energy_ev_natom\"] = y_pred_Ef\n",
    "sub[\"bandgap_energy_ev\"] = y_pred_Eg\n",
    "sub.to_csv(\"catboost_pca.csv\", index=False)\n",
    "err1.append(e1)\n",
    "err2.append(e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "250ac452-0ae6-431b-a240-3b2bc05a21f7",
    "_uuid": "1f539eadb1c050d131b7dcc96552c9c30dfae441",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "#sub['id'] = ['cat+cell','cat+cell+nonlin','cat+cell+bond','cat+cell+vol','cat+cell+bond+vol','Encode+Scale','PCA']\n",
    "sub['Ef_error'] = np.array(err1)\n",
    "sub['Eg_error'] = np.array(err2)\n",
    "sub.to_csv(\"error.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cb5c817c-7163-4519-bfa2-829a729e81ff",
    "_uuid": "e50b8ae5459816b98f709275579970bc3159d15c",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "64855b50-2684-492d-9163-369693bcd767",
    "_uuid": "3bfeaa733480e263d29c5ff149e05fac9e957965",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "47820841-661b-433e-aa72-f8e664da1590",
    "_uuid": "7297dde91b0d3cc7407f33602d9398c11468c069",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
